{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Hidden Markov Models\n",
    "\n",
    "Implementation of example from wikipedia.\n",
    "\n",
    "Doctor records symptoms of patient each day. Symptom can be 0, 1 or 2. Doctor needs to decide if the patient is healthy (0) or has a fever (1). Transition probabilties described by a. Emission probabilties by e and the initial probability distribution by p. The observed symptoms are in the list, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[.7,.3],[.4,.6]])\n",
    "#a = np.array([[.9,.1],[.1,.9]])\n",
    "e = np.array([[.5,.4,.1],[.1,.3,.6]])\n",
    "p = np.array([.6,.4])\n",
    "ys = [0,1,2]\n",
    "path = np.zeros((len(ys),2))\n",
    "for i,y in enumerate(ys):\n",
    "    tempP = np.zeros((2,2))\n",
    "    if (i==0):\n",
    "        transition_probs = np.array([[1.,0.],[0.,1.]]) #no transitions the first iteration\n",
    "    else:\n",
    "        transition_probs = a\n",
    "    for s in range(2):\n",
    "        for t in range(2):\n",
    "            tempP[s,t] = transition_probs[s,t]*e[t,y]*p[s]\n",
    "    p = np.max(tempP,axis=0)\n",
    "    idx = np.argmax(p)    \n",
    "    p = p / np.sum(p)\n",
    "    path[i,:] = np.argmax(tempP,axis=0)\n",
    "    #print tempP\n",
    "node = np.argmax(p)\n",
    "route = []\n",
    "for step in path[::-1]:\n",
    "    route.insert(0,int(node))\n",
    "    node = step[node]\n",
    "print route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def HMM_viterbi(a,e,p,ys):\n",
    "    #a=transition matrix, e=emission matrix, p=initial state, ys=observations\n",
    "    Nstates = a.shape[0]\n",
    "    path = np.zeros((len(ys),Nstates))\n",
    "    for i,y in enumerate(ys):\n",
    "        tempP = np.zeros((Nstates,Nstates))\n",
    "        if (i==0):\n",
    "            transition_probs = np.eye(Nstates) #no transitions the first iteration\n",
    "        else:\n",
    "            transition_probs = a\n",
    "        for s in range(Nstates):\n",
    "            for t in range(Nstates):\n",
    "                tempP[s,t] = transition_probs[s,t]*e[t,y]*p[s]\n",
    "        p = np.max(tempP,axis=0)\n",
    "        idx = np.argmax(p)    \n",
    "        p = p / np.sum(p)\n",
    "        path[i,:] = np.argmax(tempP,axis=0)\n",
    "        #print tempP\n",
    "    node = np.argmax(p)\n",
    "    route = []\n",
    "    for step in path[::-1]:\n",
    "        route.insert(0,int(node))\n",
    "        node = step[node]\n",
    "    return route\n",
    "    \n",
    "a = np.array([[.7,.3],[.4,.6]])\n",
    "e = np.array([[.5,.4,.1],[.1,.3,.6]])\n",
    "p = np.array([.6,.4])\n",
    "ys = [0,1,2]\n",
    "HMM_viterbi(a,e,p,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2, json\n",
    "from threading import Thread\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class Test():\n",
    "    def geonames_api_query(self,place):\n",
    "        name = place['word']\n",
    "        from urllib import urlencode\n",
    "        name = name.encode('utf8')\n",
    "        #url = 'http://api.geonames.org/searchJSON?name_equals=%s&featureCode=PPLA2&featureCode=PPLX&featureCode=PPLA3&featureCode=PPLA4&featureCode=PPLA&featureCode=PPLC&maxRows=10&username=lionfish' % name\n",
    "        url = 'http://api.geonames.org/searchJSON?name_equals=%s&featureCode=ADM1&featureCode=PCLI&featureCode=PPLX&featureCode=PPLA2&featureCode=ADM2&featureCode=ADM3&featureCode=ADM4&featureCode=PPLA3&featureCode=PPLA4&featureCode=PPLA&featureCode=PPLC&maxRows=10&username=lionfish' % name\n",
    "        #http://api.geonames.org/searchJSON?name_equals=burma&maxRows=10&username=lionfish\n",
    "        raw_json = urllib2.urlopen(url).readline() \n",
    "        data = json.loads(raw_json)\n",
    "        if 'geonames' not in data:\n",
    "            place['found'] = False\n",
    "            return\n",
    "        \n",
    "        place['found'] = False\n",
    "        lastpop = -1\n",
    "        for placedata in data['geonames']:\n",
    "            if placedata['name'].lower()==name.lower():\n",
    "                if placedata['population']>lastpop: #go with the biggest\n",
    "                    lastpop = placedata['population']\n",
    "                    place['lat'] = placedata['lat']\n",
    "                    place['lng'] = placedata['lng']\n",
    "                    place['raw'] = placedata                \n",
    "                    place['found'] = True\n",
    "                \n",
    "            \n",
    "\n",
    "    def get_places(self,data):\n",
    "        s = WordNetLemmatizer()\n",
    "        places = []\n",
    "        for like in data['likes']['data']:\n",
    "            datetime = like['created_time']\n",
    "            for fullword in like['name'].split(' '):\n",
    "                word = s.lemmatize(fullword.lower()) #strips -s etc from end of word\n",
    "                if word in words.words():\n",
    "                    continue \n",
    "                places.append({'word':word,'datetime':datetime})\n",
    "       \n",
    "        threads = []\n",
    "        for place in places:\n",
    "            t = Thread(target = self.geonames_api_query, args=(place,))\n",
    "            threads.append(t)\n",
    "            t.start()\n",
    "\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "        return places\n",
    "            \n",
    "t = Test()\n",
    "\n",
    "\n",
    "with open('facebookdataexample.txt') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "            \n",
    "places = t.get_places(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'United Kingdom',\n",
       " u'United Kingdom',\n",
       " u'Uganda',\n",
       " u'United Kingdom',\n",
       " u'Uganda',\n",
       " u'United Kingdom',\n",
       " u'United Kingdom',\n",
       " u'South Africa',\n",
       " u'United Kingdom',\n",
       " u'Malawi',\n",
       " u'United Kingdom',\n",
       " u'United Kingdom',\n",
       " u'United Kingdom',\n",
       " u'United Kingdom']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p['raw']['countryName'] for p in places if p['found']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within\n",
      "Europe & Central Asia\n",
      "United Kingdom\n"
     ]
    }
   ],
   "source": [
    "import shapefile\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def getcountry(points):\n",
    "    ppoints = []\n",
    "    res = []\n",
    "    for pnti, pnt in enumerate(points):\n",
    "        ppoints.append(Point(pnt[0],pnt[1])) #convert all points to Point() class\n",
    "        res.append(None) #we prefill our results list with a not-found \"None\"\n",
    "    recs = []\n",
    "    sf = shapefile.Reader('countryboundaries/world-country-boundaries.shp')\n",
    "    #sf = shapefile.Reader('cb/ne_110m_admin_0_countries.shp')\n",
    "    for i in range(sf.numRecords):\n",
    "        shp = sf.shape(i)\n",
    "        rec = sf.record(i)\n",
    "        recs.append(rec)\n",
    "        bbox= shp.bbox\n",
    "     #   print bbox\n",
    "        #loop through all the points, checking if they're in each country.\n",
    "        for pnti, p in enumerate(ppoints):\n",
    "            if (rec[1]=='USA'):\n",
    "                if res[pnti]!=None:\n",
    "                    continue #TODO: Hack to handle bug where some points in the UK are set to the USA\n",
    "            if p.within(Polygon(shp.points)): \n",
    "                print \"Within\"\n",
    "                countryname = rec[3]\n",
    "                regionname = rec[57]\n",
    "                res[pnti] = i,rec,points[pnti]\n",
    "    return res, recs\n",
    "p = [(-1.,53.)]\n",
    "res,rec= getcountry(p)\n",
    "\n",
    "print regionname\n",
    "print countryname\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### points = []\n",
    "for p in places:\n",
    "    if p['found']:\n",
    "        points.append((float(p['lng']),float(p['lat']),p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res, recs = getcountry(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#probability of staying in the same country for each like\n",
    "pStay = 0.9 #0.8\n",
    "#the following probabilities get spread across...\n",
    " #...the countries in the region\n",
    "pMoveInRegion = 0.4 #0.1\n",
    " #...all countries\n",
    "pMove = 0.1\n",
    "pEmitRightCountry = 4./14. #only calculated approximately; 4/14 from my own facebook.\n",
    "\n",
    "N = len(recs)\n",
    "a = np.zeros((N,N))\n",
    "for i,recI in enumerate(recs):\n",
    "    for j,recJ in enumerate(recs):\n",
    "        if recI[2]==recJ[2]: #if in same region of world\n",
    "            a[i,j] = 1\n",
    "a = pMoveInRegion*(a/np.tile(np.sum(a,axis=0),(N,1)))\n",
    "a[range(N),range(N)] = np.ones(N)*pStay\n",
    "a = a + pMove/N\n",
    "\n",
    "#calculation was a bit rough, so normalising\n",
    "a = a/np.tile(np.sum(a,axis=0),(N,1))\n",
    "#probability of 'emitting' that you are in your current country or not\n",
    "e = (1-pEmitRightCountry) * np.ones((N,N))/(N)\n",
    "e = e + np.eye(N)*pEmitRightCountry\n",
    "p = np.ones(N)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-57d3634a5fb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "res.insert(2,res[2])\n",
    "res.insert(2,res[2])\n",
    "res.insert(2,res[2])\n",
    "\n",
    "\n",
    "#probability of staying in the same country for each like\n",
    "pStay = 0.9 #0.8\n",
    "#the following probabilities get spread across...\n",
    " #...the countries in the region\n",
    "pMoveInRegion = 0.4 #0.1\n",
    " #...all countries\n",
    "pMove = 0.1\n",
    "pEmitRightCountry = 4./14. #only calculated approximately; 4/14 from my own facebook.\n",
    "\n",
    "N = len(recs)\n",
    "a = np.zeros((N,N))\n",
    "for i,recI in enumerate(recs):\n",
    "    for j,recJ in enumerate(recs):\n",
    "        if recI[2]==recJ[2]: #if in same region of world\n",
    "            a[i,j] = 1\n",
    "a = pMoveInRegion*(a/np.tile(np.sum(a,axis=0),(N,1)))\n",
    "a[range(N),range(N)] = np.ones(N)*pStay\n",
    "a = a + pMove/N\n",
    "\n",
    "#calculation was a bit rough, so normalising\n",
    "a = a/np.tile(np.sum(a,axis=0),(N,1))\n",
    "#probability of 'emitting' that you are in your current country or not\n",
    "e = (1-pEmitRightCountry) * np.ones((N,N))/(N)\n",
    "e = e + np.eye(N)*pEmitRightCountry\n",
    "p = np.ones(N)/N\n",
    "\n",
    "guess = HMM_viterbi(a,e,p,[r[0] for r in res])\n",
    "print [(r[0],r[2][2]['datetime'][0:4]) for r in res]\n",
    "print guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((2010, 'Malawi'), 1), ((2009, 'UK'), 1), ((2012, 'UK'), 1)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-9c24e8325675>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mnewlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnewlist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-9c24e8325675>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(k)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mnewlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnewlist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'tuple'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counts = collections.Counter(guess)\n",
    "c = counts.items()\n",
    "print c\n",
    "newlist = sorted(c, key=lambda k: -k[1]) \n",
    "print newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-65134ee42683>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnewlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mguess\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mguess\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdatetime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%Y-%m-%dT%H:%M:%S+0000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcountries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import time\n",
    "countries = []\n",
    "for item in newlist:\n",
    "    idx = (len(guess) - 1) - guess[::-1].index(item[0])\n",
    "    datetime = res[idx][2][2]['datetime']\n",
    "    t = time.strptime(datetime, '%Y-%m-%dT%H:%M:%S+0000')\n",
    "    countries.append((recs[item[0]],t))\n",
    "print [c[0][0] for c in countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since at least 2015 you've mainly lived in United Kingdom but have also lived in United States\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if len(countries)==1:\n",
    "    con = countries[0]\n",
    "    print \"Since at least %d you've lived in %s\" % (con[1][0],con[0][0])\n",
    "else:\n",
    "    con = countries[0]\n",
    "    print \"Since at least %d you've mainly lived in %s\" % (con[1][0],con[0][0]),\n",
    "    con = countries[1]\n",
    "    sys.stdout.write(\" but have also lived in %s\" % con[0][0])\n",
    "    for i,con in enumerate(countries[2:-1]):\n",
    "        sys.stdout.write(\", %s\" % (con[0][0]))\n",
    "    if len(countries)>2:\n",
    "        sys.stdout.write(\" and %s\" % countries[-1][0][0])\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf = shapefile.Reader('countryboundaries/world-country-boundaries.shp')\n",
    "#sf = shapefile.Reader('cb/ne_110m_admin_0_countries.shp')\n",
    "places = []\n",
    "for i in range(sf.numRecords):\n",
    "    places.append(sf.record(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p[0] for p in places].index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brazil', 'BRA', 'Latin America']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sdfgsdgdg'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = \"sdfgsdg\"\n",
    "msg += \"dg\"\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
