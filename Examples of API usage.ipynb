{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikic API v1.0\n",
    " \n",
    "## Overview\n",
    "\n",
    "The scikic api is an inference tool which takes a set of question/answer items and then queries a series of local and remote databases to generate conditional probability distributions over various features. The api is highly modular, and some modules don't use this probabilistic framework, for example the music module simply contacts api.bandsintown.com to provide useful suggestions about local bands to go and see.\n",
    "\n",
    "The conditional probabilities are combined using a Bayesian network, using the pyMC module. Each module can provide pyMC 'features' which create functions to output the relevant probability distributions.\n",
    "\n",
    "## Question/Answer dictionaries\n",
    "\n",
    "The questions and answers are organised to be in 4 value tuples, containing:\n",
    "\n",
    "- dataset: lets the system know which class to instantiate etc, examples: postcode, census, movielens, ...etc\n",
    "- dataitem: used by classes to know which aspect of the dataset. For example in the movielens dataset, one could be interested in whether the user's seen a film or what rating they've given the film.\n",
    "- detail: often unused by the classes, could be, for example, the id of the film we want to know about.\n",
    "- answer: the user's answer.\n",
    "\n",
    "## Future Changes\n",
    "\n",
    "Heads-up about a couple of changes:\n",
    "\n",
    " - Vasily suggested I move the 'action' selection out and make it part of the URL, to make it more RESTful.\n",
    " - I'll be combining the API query that gets the question string, with the one that generates the 'raw' question tuple. Originally the API was designed when it was run on the same server as the code that was querying it, so extra API calls didn't cost much. As the calls will now be remote, they need combining.\n",
    " - The version number will be used in future.\n",
    " - The API doesn't currently check the key. Obviously this will be implemented in future.\n",
    "\n",
    "## Available actions\n",
    "\n",
    "Here are some examples of the API in action. A POST request is used for the query, in case the data we're sending is too large to fit in a GET request. Note it always uses POST (so not using the range of HTTP queries).\n",
    "\n",
    "### 1. Get a suggestion for a question to answer *[action: question]*\n",
    "\n",
    "#### Parameters\n",
    "One passes to this call in data, a dictionary containing:\n",
    " - 'questions_asked'\n",
    " - 'unprocessed_questions'\n",
    " - 'facts'\n",
    " - 'target'\n",
    "\n",
    "The 'questions_asked' include all the questions we've asked, so we don't ask the same question again.\n",
    "The 'facts' dictionary contains information that we've found from earlier questions, etc. It allows caching of the calculations from earlier calls to the API.\n",
    "The 'unprocessed_questions' are a list of question/answers that we've asked before, that haven't had their results added to the 'facts' dictionary.\n",
    "The 'target' item is currently unused, but in the future will allow the choice of question to be selected to maximise the information about a particular feature.\n",
    "\n",
    "#### Returns\n",
    "\n",
    "This call returns a dictionary containing two things:\n",
    "\n",
    " - a 'facts' dictionary - this you can pass back in future so that the method doesn't have to recalculate or generate earlier results.\n",
    " - a 'question' dictionary, containing the dictionary describing the question, e.g. {dataset,dataitem,detail}.\n",
    "\n",
    "'data' contains a list of previous asked (and answered) questions, to allow an optimum question to be asked.\n",
    "\n",
    "#### Usage example\n",
    "\n",
    "1. One might initially call this method with all these fields being empty. The method will return an empty 'facts' dictionary and a question dictionary for the first question you want to ask. \n",
    "2. Once you have an answer from the user you would call the method again, this time with the question/answer tuple as both 'questions_asked' and 'unprocessed_questions'.\n",
    "3. The method will return a facts dictionary now, potentially with some results from the processing of the last answer, and another question for you to ask. \n",
    "4. When you call the method a third time (with the user's second answer), you'll pass all the question/answer tuples that you've asked so far in 'questions_asked' and the last question/answer tuple in 'unprocessed_questions'. You'll also pass the new facts dictionary, that now has some content in it.\n",
    "5. This process continues, with the facts dictionary growing each time, the 'questions_asked' growing too, and each time you just have one item in 'unprocessed_questions'.\n",
    "\n",
    "To summarise:\n",
    "\n",
    "Generating a question requires a dictionary of 'questions_asked', 'facts' and 'target'. The 'questions_asked' is a list of dictionaries of previous questions, that you want to avoid asking again.\n",
    "The 'unprocessed_questions' are questions that you've asked already and that haven't been incorporated into the 'facts' dictionary.\n",
    "\n",
    "Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The url of the API currently (in the long run we should give the backend a domain, maybe api.scikic.org?)\n",
    "#apiurl = 'http://api.scikic.org' #production api\n",
    "apiurl = 'http://dev.scikic.org/api/' #development api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\"facts\": {}, \"question\": {\"detail\": \"\", \"dataitem\": \"travel\", \"dataset\": \"lifestyle\"}}\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "#We provide data about previous questions etc:\n",
    "#data consists of a dictionary of (all of these are optional):\n",
    "\n",
    "#'questions_asked': An array of previous questions and answers we've asked, consists of a list of dictionaries.\n",
    "questions_asked = [{'dataset':'postal','dataitem':'postcode','detail':''},{\"detail\": \"\", \"dataitem\": \"favourite_artist\", \"dataset\": \"music\"}]\n",
    "\n",
    "#none of the questions that have been asked before have been processed.\n",
    "unprocessed_questions = questions_asked\n",
    "\n",
    "#'facts': If you've run the inference query and stored a copy of the facts dictionary you can pass it back.\n",
    "#this makes it quicker. In this case we've not yet had any questions processed.\n",
    "facts = {}\n",
    "\n",
    "#'target': What feature we want to know more about (example: 'age', 'gender', 'location') NOT YET IMPLEMENTED\n",
    "#not used. All these items are optional, so we just don't include it.\n",
    "\n",
    "#Build the dictionary:\n",
    "data = {'unprocessed_questions':unprocessed_questions,'questions_asked':questions_asked,'facts':facts}\n",
    "\n",
    "#put it into the payload of the request. This also includes the version, the api key we're using and the action we want (in this case generate a question)\n",
    "payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'question'}\n",
    "r = requests.post(apiurl,json=payload)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it has output:\n",
    "\n",
    " - the facts dictionary: Empty\n",
    " - the question it suggests we ask, which in this case is from the movielens dataset class, and is asking if they've seen movie number 2541.\n",
    " \n",
    "Currently we don't really know what this question means, we need to get a text string of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get a text string of the question *[action: questionstring]*\n",
    "\n",
    "Once you have a tuple, like the one generated above, you may want a human readable string of the question. This method takes the tuple (in data) and returns a dictionary, of:\n",
    "\n",
    "- 'text' - the actual string of the question (e.g. \"Who's your favourite band or artist?\")\n",
    "- 'type' - the type of question (it might just want a text reply, so this would equal 'text' or it might be a choice, and so would say 'select'\n",
    "- 'options' - optional, and is included if the type is 'select'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\"type\": \"text\", \"question\": \"What\\'s your postcode?\"}\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = {'dataset':'postal','dataitem':'postcode','detail':''}\n",
    "payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'questionstring'}\n",
    "r = requests.post(apiurl,json=payload)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the dictionary `{'dataset':'postal','dataitem':'postcode','detail':''}` gets converted to the question \"`What's your postcode?`\" with type \"`text`\" (i.e. the user can type anything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\"type\": \"select\", \"question\": \"Is your current home in or near Sheffield, UK?\", \"options\": [\"yes\", \"no\", \"don\\'t know\"]}\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data = {'dataset':'geoloc','dataitem':'nearcity','detail':json.dumps({'city':'Sheffield','country':'UK'})}\n",
    "payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'questionstring'}\n",
    "r = requests.post(apiurl,json=payload)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the dictionary \"`{'dataset':'geoloc','dataitem':'nearcity','detail':json.dumps({'city':'Sheffield','country':'UK'})}`\" gets converted to \"`Is your home in or near Sheffield, UK?`\", which is a select type of question with the options yes, no or don't know.\n",
    "\n",
    "Note that the detail contained a dictionary, this varies by the dataset module involved.\n",
    "\n",
    "###Why did the question string generation get separated from question selection?\n",
    "The current frontend stores the question that needs asking next, so:\n",
    "\n",
    "  1. We know which question any answer given is for.\n",
    "  2. We can ask the same question when the user returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inference *[action: inference]*\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "The data dictionary should contain three things, similar to the \"action: question\" above,\n",
    "\n",
    "- questions_asked - list of question tuples that we've asked (with their answers)\n",
    "- unprocessed_questions - list of question tuples that we've asked (with their answers), that have not yet been added to the facts dictionary.\n",
    "- facts - the current 'facts' dictionary (possibly provided by earlier calls using action:question)\n",
    "\n",
    "Returns a dictionary of:\n",
    "\n",
    "##### features\n",
    "This is a dictionary of things that have probabilities associated, for example one of its items is 'household' with the following fields:\n",
    " \n",
    "     {\"distribution\": [0.029, 0.058, 0.23, 0.034, 0.070, 0.026, 0.055, 0.036, 0.14, 0.024, 0.023, 0.035, 0.24], \"quartiles\": {\"upper\": 11, \"lower\": 2, \"mean\": 6.46}}\n",
    " \n",
    " where the distribution is how likely the person is to be in each of the categories of a household (these categories can be found in the metadata from the module, or elsewhere). The quartiles don't mean much here as this is properly categorical data. This makes more sense in data such as age.\n",
    " \n",
    "##### facts\n",
    "As mentioned previously is a set of truths about the user generated from processing their answers.\n",
    "\n",
    "##### Insights\n",
    "This is a list of strings, generated by each module, here is an example:\n",
    " \n",
    "     [\"I can\\'t tell which country you\\'re in, just looking at your facebook likes, as I can\\'t see your facebook likes!\", \"You are aged between 20 and 33.\", \"You don\\'t have children living at home\", \" I think you are Christian or of no religion.\"]}\n",
    " \n",
    "Note regarding the distribution above: If some probabilities are zero towards the end of a list then the list will be truncated. For example if inference is certain the user is a male, then the output list will be {\"factor_gender\":[1.0]}. If they are definitely female it will be {\"factor_gender\":[0.0, 1.0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example call using action:inference\n",
    "\n",
    "Below we set up the data dictionary with one question asked (and answered) regarding postcode. It also contains the same question/answer dictionary as an unprocessed question. The facts dictionary is empty.\n",
    "\n",
    "The output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"facts\": {\"guess_loc\": {}, \"first_name\": \"Alan\", \"where\": {\"ukcensus\": [{\"item\": \"E00172420\", \"probability\": 1.0, \"level\": \"oa\"}], \"city\": [{\"item\": [\"Sheffield\", \"uk\"], \"probability\": 1.0}], \"country\": [{\"item\": \"gb\", \"probability\": 1.0}]}, \"where_history\": {\"error\": \"no_fb_likes\"}}, \"features\": {\"religion\": {\"distribution\": [0.24444444444444444, 0.036, 0.03866666666666667, 0.04133333333333333, 0.064, 0.035111111111111114, 0.044444444444444446, 0.496], \"quartiles\": {\"upper\": 7, \"lower\": 1, \"mean\": 4.407555555555556}}, \"household\": {\"distribution\": [0.029333333333333333, 0.03422222222222222, 0.19511111111111112, 0.028444444444444446, 0.023555555555555555, 0.042222222222222223, 0.04711111111111111, 0.050222222222222224, 0.29244444444444445, 0.029777777777777778, 0.030222222222222223, 0.035555555555555556, 0.16177777777777777], \"quartiles\": {\"upper\": 9, \"lower\": 2, \"mean\": 6.691555555555555}}, \"factor_gender\": {\"distribution\": [1.0], \"quartiles\": {\"upper\": 0, \"lower\": 0, \"mean\": 0.0}}, \"oa\": {\"distribution\": [1.0], \"quartiles\": {\"upper\": 0, \"lower\": 0, \"mean\": 0.0}}, \"factor_age\": {\"distribution\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011555555555555555, 0.04755555555555555, 0.028888888888888888, 0.052, 0.029333333333333333, 0.020444444444444446, 0.024, 0.029777777777777778, 0.04844444444444444, 0.013777777777777778, 0.072, 0.009777777777777778, 0.03288888888888889, 0.052, 0.04133333333333333, 0.02311111111111111, 0.016888888888888887, 0.004888888888888889, 0.028888888888888888, 0.010222222222222223, 0.014222222222222223, 0.014222222222222223, 0.0, 0.014222222222222223, 0.017333333333333333, 0.009777777777777778, 0.020444444444444446, 0.015555555555555555, 0.015111111111111112, 0.0, 0.05288888888888889, 0.010222222222222223, 0.0, 0.0, 0.0, 0.05288888888888889, 0.0, 0.0, 0.016888888888888887, 0.022222222222222223, 0.0, 0.024, 0.016888888888888887, 0.0, 0.019555555555555555, 0.0, 0.0, 0.0, 0.028888888888888888, 0.00044444444444444447, 0.024888888888888887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011555555555555555], \"quartiles\": {\"upper\": 51, \"lower\": 29, \"mean\": 40.36755555555556}}}, \"insights\": [\"Note: I can't see your facebook likes.\", \"You're called Alan\", \"People with your name are mostly aged between 39 and 86\", \"Your name was most popular in about 1915\", \"You are aged between 29 and 51.\", \"You are male\", \"You don't have children living at home\", \" I think you are Christian or of no religion.\", \"Half the people in your neighbourhood are younger than 25 years old.\", \"People in your area are 3.0 times more likely to go to work on foot than the national average.\", \"[[ 0.5095046   0.36174118  2.98274457  0.83956473  0.75262965  0.41697102\\n   0.64991456  0.66625789  1.84376019  0.89615631  0.86009729  1.85741302]]\", \"[[ 0.00401606  0.00803213  0.20883534  0.28514056  0.02811245  0.00401606\\n   0.03212851  0.02409639  0.05220884  0.03212851  0.30522088  0.01606426]]\", \"[ 0.00788229  0.02220408  0.07001449  0.33962904  0.0373523   0.00963152\\n  0.04943498  0.03616675  0.0283165   0.03585146  0.35486786  0.00864873]\"]}\n",
      "\n",
      "==Facts==\n",
      "{u'guess_loc': {}, u'first_name': u'Alan', u'where': {u'ukcensus': [{u'item': u'E00172420', u'probability': 1.0, u'level': u'oa'}], u'country': [{u'item': u'gb', u'probability': 1.0}], u'city': [{u'item': [u'Sheffield', u'uk'], u'probability': 1.0}]}, u'where_history': {u'error': u'no_fb_likes'}}\n",
      "\n",
      "==Features==\n",
      "religion\n",
      "{u'distribution': [0.24444444444444444, 0.036, 0.03866666666666667, 0.04133333333333333, 0.064, 0.035111111111111114, 0.044444444444444446, 0.496], u'quartiles': {u'upper': 7, u'lower': 1, u'mean': 4.407555555555556}}\n",
      "household\n",
      "{u'distribution': [0.029333333333333333, 0.03422222222222222, 0.19511111111111112, 0.028444444444444446, 0.023555555555555555, 0.042222222222222223, 0.04711111111111111, 0.050222222222222224, 0.29244444444444445, 0.029777777777777778, 0.030222222222222223, 0.035555555555555556, 0.16177777777777777], u'quartiles': {u'upper': 9, u'lower': 2, u'mean': 6.691555555555555}}\n",
      "oa\n",
      "{u'distribution': [1.0], u'quartiles': {u'upper': 0, u'lower': 0, u'mean': 0.0}}\n",
      "factor_gender\n",
      "{u'distribution': [1.0], u'quartiles': {u'upper': 0, u'lower': 0, u'mean': 0.0}}\n",
      "factor_age\n",
      "{u'distribution': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011555555555555555, 0.04755555555555555, 0.028888888888888888, 0.052, 0.029333333333333333, 0.020444444444444446, 0.024, 0.029777777777777778, 0.04844444444444444, 0.013777777777777778, 0.072, 0.009777777777777778, 0.03288888888888889, 0.052, 0.04133333333333333, 0.02311111111111111, 0.016888888888888887, 0.004888888888888889, 0.028888888888888888, 0.010222222222222223, 0.014222222222222223, 0.014222222222222223, 0.0, 0.014222222222222223, 0.017333333333333333, 0.009777777777777778, 0.020444444444444446, 0.015555555555555555, 0.015111111111111112, 0.0, 0.05288888888888889, 0.010222222222222223, 0.0, 0.0, 0.0, 0.05288888888888889, 0.0, 0.0, 0.016888888888888887, 0.022222222222222223, 0.0, 0.024, 0.016888888888888887, 0.0, 0.019555555555555555, 0.0, 0.0, 0.0, 0.028888888888888888, 0.00044444444444444447, 0.024888888888888887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011555555555555555], u'quartiles': {u'upper': 51, u'lower': 29, u'mean': 40.36755555555556}}\n",
      "\n",
      "==Text insights==\n",
      "[u\"Note: I can't see your facebook likes.\", u\"You're called Alan\", u'People with your name are mostly aged between 39 and 86', u'Your name was most popular in about 1915', u'You are aged between 29 and 51.', u'You are male', u\"You don't have children living at home\", u' I think you are Christian or of no religion.', u'Half the people in your neighbourhood are younger than 25 years old.', u'People in your area are 3.0 times more likely to go to work on foot than the national average.', u'[[ 0.5095046   0.36174118  2.98274457  0.83956473  0.75262965  0.41697102\\n   0.64991456  0.66625789  1.84376019  0.89615631  0.86009729  1.85741302]]', u'[[ 0.00401606  0.00803213  0.20883534  0.28514056  0.02811245  0.00401606\\n   0.03212851  0.02409639  0.05220884  0.03212851  0.30522088  0.01606426]]', u'[ 0.00788229  0.02220408  0.07001449  0.33962904  0.0373523   0.00963152\\n  0.04943498  0.03616675  0.0283165   0.03585146  0.35486786  0.00864873]']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "postcode = 's63af' #gl69en' #s63af\n",
    "questions_asked = [{'dataset':'postal','dataitem':'postcode','detail':'','answer':postcode}]\n",
    "unprocessed_questions = [{'dataset':'postal','dataitem':'postcode','detail':'','answer':postcode}]\n",
    "facts = {}\n",
    "\n",
    "#Additional info from facebook\n",
    "fb_data = json.dumps({'reply':json.dumps({'first_name':'Alan'})})\n",
    "questions_asked.append({'dataset':'facebook','dataitem':'','detail':'','answer':fb_data})\n",
    "unprocessed_questions.append({'dataset':'facebook','dataitem':'','detail':'','answer':fb_data})\n",
    "\n",
    "\n",
    "data = {'questions_asked':questions_asked,'unprocessed_questions':unprocessed_questions,'facts':facts}\n",
    "payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'inference'}\n",
    "r = requests.post(apiurl,json=payload)\n",
    "print r.content\n",
    "result = json.loads(r.content)\n",
    "print \"==Facts==\"\n",
    "print result['facts']\n",
    "print \"\"\n",
    "print \"==Features==\"\n",
    "for feat in result['features']:\n",
    "    print feat\n",
    "    print result['features'][feat]\n",
    "print \"\"\n",
    "print \"==Text insights==\"\n",
    "print result['insights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example above one can see that after just processing the answer about postcode, quite a bit of new info has been generated.\n",
    "\n",
    "First the facts dictionary. This is often dataset specific stuff, although I've tried to make things compatable between datasets.\n",
    "\n",
    " - 'guess_loc': {} - info on whether it guessed the location of the user from IP address (I think)\n",
    " - 'where': - the dictionary describing the location of the user's home. This is quite tricky, as different sources of data have different resolutions, etc about this.\n",
    "     - {'ukcensus': [{'item': 'E00172420', 'probability': 1.0, 'level': 'oa'}] - In terms of the UK census, with have a list of output areas for this person's home. This list only has one item in it. Each item in the list has a probability associated, in this case the probability is 1.0: We are certain the person is in that output area.\n",
    "     - 'country': [{'item': 'gb', 'probability': 1.0}] - Which country they're in. A list of countries with associated probabilities.\n",
    "     - 'city': [{'item': ['Sheffield', 'uk'], 'probability': 1.0}]} - which city their in (with probabilites).\n",
    "     - 'where_history': {u'error': u'no_fb_likes'}} - if we have access to facebook likes, it tries to generate a history of where the person's lived. But the error item means that it's not managed to get hold of the likes to do this.\n",
    "\n",
    "Next the features dictionary. Different datasets provide different conditional probability distributions. Each distribution has at least two features associated. If they are not in the list already the module adds them, thus one has a list of features at the end.\n",
    "\n",
    "The value of these features is then estimated using MCMC with the pyMC module.\n",
    "\n",
    "The example above has five features: religion, household, (census) output area, gender and age. They're all catagorical (for now) although that's purely due to the type of data that we have about them.\n",
    "\n",
    "Looking just at the household feature: [0.022222222222222223, 0.05688888888888889, 0.23466666666666666, 0.03244444444444444, 0.08266666666666667, 0.028, 0.059111111111111114, 0.03955555555555555, 0.14222222222222222, 0.024, 0.024444444444444446, 0.028444444444444446, 0.22533333333333333]\n",
    "\n",
    "Each value refers to the probability of being of a given type of household (the labels associated are available via the metadata of the module).\n",
    "\n",
    "Finally there are insights, these are simple strings of facts about the person:\n",
    " - \"I can't tell which country you're in, just looking at your facebook likes, as I can't see your facebook likes!\" - this first one is more of an error message warning us that we couldn't get to their facebook like data.\n",
    " - \"You are aged between 19 and 31\"\n",
    " - \"I think you are Christian or of no religion\"\n",
    " \n",
    "Here's another example, with an american zip code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\"facts\": {\"guess_loc\": {}, \"where\": {\"uscensus\": [{\"item\": [\"04\", \"015\", \"950100\", \"1\"], \"probability\": 0.514, \"level\": \"blockgroup\"}, {\"item\": [\"04\", \"015\", \"950100\", \"3\"], \"probability\": 0.486, \"level\": \"blockgroup\"}], \"city\": [{\"item\": [\"Colorado City, AZ\", \"us\"], \"probability\": 1.0}], \"country\": [{\"item\": \"us\", \"probability\": 1.0}]}, \"where_history\": {\"error\": \"no_fb_likes\"}}, \"features\": {\"bg\": {\"distribution\": [0.33155555555555555, 0.6684444444444444], \"quartiles\": {\"upper\": 1, \"lower\": 0, \"mean\": 0.6684444444444444}}, \"factor_gender\": {\"distribution\": [0.30844444444444447, 0.6915555555555556], \"quartiles\": {\"upper\": 1, \"lower\": 0, \"mean\": 0.6915555555555556}}, \"factor_age\": {\"distribution\": [0.010666666666666666, 0.029333333333333333, 0.03777777777777778, 0.028444444444444446, 0.024888888888888887, 0.044444444444444446, 0.028888888888888888, 0.04488888888888889, 0.024888888888888887, 0.03688888888888889, 0.03822222222222222, 0.026222222222222223, 0.028888888888888888, 0.029333333333333333, 0.029777777777777778, 0.02, 0.02, 0.02311111111111111, 0.028888888888888888, 0.027555555555555555, 0.015555555555555555, 0.019555555555555555, 0.004888888888888889, 0.009333333333333334, 0.0071111111111111115, 0.0035555555555555557, 0.008444444444444444, 0.008, 0.006222222222222222, 0.007555555555555556, 0.008, 0.0071111111111111115, 0.008, 0.012444444444444444, 0.008, 0.008888888888888889, 0.013333333333333334, 0.011555555555555555, 0.015555555555555555, 0.011555555555555555, 0.016888888888888887, 0.015555555555555555, 0.008, 0.016, 0.012888888888888889, 0.005333333333333333, 0.004888888888888889, 0.0017777777777777779, 0.0026666666666666666, 0.003111111111111111, 0.008444444444444444, 0.007555555555555556, 0.008444444444444444, 0.005333333333333333, 0.0071111111111111115, 0.0022222222222222222, 0.0044444444444444444, 0.004, 0.0057777777777777775, 0.0013333333333333333, 0.0071111111111111115, 0.006666666666666667, 0.0008888888888888889, 0.0013333333333333333, 0.0008888888888888889, 0.0035555555555555557, 0.0026666666666666666, 0.0035555555555555557, 0.004888888888888889, 0.0017777777777777779, 0.004, 0.003111111111111111, 0.006666666666666667, 0.0022222222222222222, 0.003111111111111111, 0.0035555555555555557, 0.003111111111111111, 0.0035555555555555557, 0.0044444444444444444, 0.0022222222222222222, 0.00044444444444444447, 0.0013333333333333333, 0.0013333333333333333, 0.0008888888888888889, 0.00044444444444444447, 0.0008888888888888889, 0.00044444444444444447, 0.0, 0.00044444444444444447, 0.0008888888888888889, 0.00044444444444444447, 0.00044444444444444447, 0.0, 0.0008888888888888889, 0.0, 0.0, 0.0, 0.0008888888888888889, 0.0008888888888888889, 0.00044444444444444447], \"quartiles\": {\"upper\": 37, \"lower\": 8, \"mean\": 23.63288888888889}}}, \"insights\": [\"Note: I can\\'t see your facebook likes.\", \"You are aged between 8 and 37.\"]}\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "questions_asked = [{'dataset':'postal','dataitem':'zipcode','detail':'','answer':'86021'}]\n",
    "unprocessed_questions = [{'dataset':'postal','dataitem':'zipcode','detail':'','answer':'86021'}]\n",
    "facts = {}\n",
    "        \n",
    "data = {'questions_asked':questions_asked,'unprocessed_questions':unprocessed_questions,'facts':facts}\n",
    "\n",
    "payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'inference'}\n",
    "r = requests.post(apiurl,json=payload)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see this is similar, except the 'where' item in the dictionary has a 'uscensus' item within it. This contains two items:\n",
    "\n",
    "    {\"item\": [\"04\", \"015\", \"950100\", \"1\"], \"probability\": 0.514, \"level\": \"blockgroup\"}\n",
    "    {\"item\": [\"04\", \"015\", \"950100\", \"3\"], \"probability\": 0.486, \"level\": \"blockgroup\"}\n",
    "\n",
    "Because zipcodes cover quite large areas, it doesn't know which blockgroup the person's home is in, as the zip code spans more than one blockgroup. It therefore gives the probability of being in the two.\n",
    "\n",
    "The US census module doesn't know about religion, so doesn't have a conditional probability distribution about it, so no religion feature is created. The features that are created are:\n",
    "\n",
    " - bg (block group)\n",
    " - gender\n",
    " - age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Metadata *[action: metadata]*\n",
    "\n",
    "Some of the classes provide metadata about the results. Use the 'metadata' action to retrieve these. Pass a dictionary in 'data' with the name of the dataset, or leave empty to get all the metadata of all the classes.\n",
    "\n",
    "In this example we display the citation information for the 'babynames' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ONS provide statistics on the distribution of the names of baby's in the UK: <a href=\"http://www.ons.gov.uk/ons/about-ons/business-transparency/freedom-of-information/what-can-i-request/published-ad-hoc-data/pop/august-2014/baby-names-1996-2013.xls\">1996-2013</a> and <a href=\"http://www.ons.gov.uk/ons/rel/vsob1/baby-names--england-and-wales/1904-1994/top-100-baby-names-historical-data.xls\">1904-1994</a>.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "data = {'dataset':'babynames'}\n",
    "payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'metadata'}\n",
    "r = requests.post(apiurl,json=payload)\n",
    "for item in json.loads(r.content):\n",
    "    if 'citation' in item:\n",
    "        print(item['citation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we get all citations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The <a href=\"facebook.com\">facebook</a> graph API\n",
      "The <a href=\"http://www.census.gov/developers/\">US census bureau</a>\n",
      "The <a href=\"http://files.grouplens.org/datasets/movielens\">movielens</a> database\n",
      "The ONS provide statistics on the distribution of the names of baby's in the UK: <a href=\"http://www.ons.gov.uk/ons/about-ons/business-transparency/freedom-of-information/what-can-i-request/published-ad-hoc-data/pop/august-2014/baby-names-1996-2013.xls\">1996-2013</a> and <a href=\"http://www.ons.gov.uk/ons/rel/vsob1/baby-names--england-and-wales/1904-1994/top-100-baby-names-historical-data.xls\">1904-1994</a>.\n",
      "The <a href=\"https://geoportal.statistics.gov.uk\">UK office of national statistics</a> (see <a href=\"http://www.ons.gov.uk/ons/guide-method/geography/products/census/lookup/other/index.html\">details</a> and <a href=\"https://geoportal.statistics.gov.uk/geoportal/catalog/search/resource/details.page?uuid={A33B0569-97E2-4F44-836C-B656A6D082B6} \">information</a>) and the US zipcode data was from <a href=\"http://mcdc.missouri.edu\">Missouri's Census Data Center.\n",
      "The <a href=\"bandsintown.com\">bandsintown.com</a> API\n",
      "The <a href=\"http://www.ons.gov.uk/ons/guide-method/census/2011/census-data/ons-data-explorer--beta-/index.html\">UK office of national statistics</a>\n",
      "The <a href=\"freegeoip.net\">freegeoip.net</a> API\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "data = {}#no dataset specified (makes it output all metadata)\n",
    "payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'metadata'}\n",
    "r = requests.post(apiurl,json=payload)\n",
    "for item in json.loads(r.content):\n",
    "    if 'citation' in item:\n",
    "        print(item['citation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typical API usage\n",
    "\n",
    "The scikic front end may use the API in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a1d3b1d3b1af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#ask the user this question\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0muserinput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_string_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mquestion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answer'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muserinput\u001b[0m \u001b[1;31m#add their answer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lionfish/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lionfish/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "#We start with no questions asked, none unprocessed, and nothing in the facts dictionary.\n",
    "questions_asked = []\n",
    "unprocessed_questions = []\n",
    "facts = {}\n",
    "\n",
    "for loop in range(3): #we'll ask three questions\n",
    "    \n",
    "    #1. get the question (populate the data dictionary & send it off)\n",
    "    data = {'unprocessed_questions':unprocessed_questions,'questions_asked':questions_asked,'facts':facts}\n",
    "    payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'question'}\n",
    "    r = requests.post(apiurl,json=payload) #>>>\n",
    "    question_query_result = json.loads(r.content)\n",
    "    \n",
    "    #if processing was done then more items will be available for 'facts':\n",
    "    facts = question_query_result['facts']\n",
    "    \n",
    "    #2. We want to get the question string itself (put the question tuple in data and send it off to the server)\n",
    "    data = question_query_result['question']\n",
    "    payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'questionstring'}\n",
    "    r = requests.post(apiurl,json=payload) #>>>\n",
    "\n",
    "    #we now have the question string\n",
    "    question_string_result = json.loads(r.content)\n",
    "    question = question_query_result['question']\n",
    "\n",
    "    #ask the user this question    \n",
    "    userinput = raw_input(question_string_result['question'])\n",
    "    question['answer'] = userinput #add their answer\n",
    "\n",
    "    #add this to the list of questions we've asked, and unprocessed questions\n",
    "    questions_asked.append(question)\n",
    "    unprocessed_questions.append(question)\n",
    "    \n",
    "#3. Once enough questions are asked we can do inference.\n",
    "#   Populate the data dictionary with questions asked,\n",
    "#   unprocessed questions and facts (as for the question query in step 1)\n",
    "data = {'questions_asked':questions_asked,'unprocessed_questions':unprocessed_questions,'facts':facts}\n",
    "payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'inference'}\n",
    "r = requests.post(apiurl,json=payload) #>>>\n",
    "inference_results = json.loads(r.content)\n",
    "\n",
    "#It generates insights from these questions, which are displayed below.\n",
    "print \"\\nInsights\\n\"\n",
    "for insight in inference_results['insights']:\n",
    "    print insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scikic System\n",
    "\n",
    "## Instances\n",
    "\n",
    "Development on the front and back ends currently takes place on the development server (currently pointed to by scikic.org, 54.77.57.28).\n",
    "\n",
    "Production is via a front end (52.19.69.129) and a server which provides the image for the backend (52.18.184.63). An autoscaling group, launch configuration and load balancer are used to provide the backend processing. The launch configuration uses the 'Production BackEnd Image' instance to produce the AMI.\n",
    "\n",
    "### Recipe to update backend\n",
    "\n",
    "1. On the dev system run nosetest.\n",
    "2. Push the changes to git\n",
    "3. On the production backend image server, pull the changes.\n",
    "4. Right click on server, create image.\n",
    "5. image name: production-backend-120116.\n",
    "\n",
    "6. Click on launch configurations\n",
    "7. Create Launch Cofiguration\n",
    "8. Select the new image name you just created\n",
    "9. Select t2.medium\n",
    "10. Name: production-backend-120116-lc\n",
    "11. Next> Delete both on termination.\n",
    "12. Select existing security group (production backend)\n",
    "13. Launch\n",
    "\n",
    "14. Autoscaling group. Select the production-backend-4-asg and click edit\n",
    "15. Select the new launch configuration\n",
    "\n",
    "\n",
    "## DNS\n",
    "\n",
    "DNS is provided by namecheap (see Neil for username/password). I've set the nameservers for scikic.org to point to the AWS Route53 DNS system.\n",
    "\n",
    "## How to configure in the future\n",
    "\n",
    "- cloudinit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Stress Testing\n",
    "\n",
    "To test how well the system copes under load, this script calls the API multiple times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 240 processes over the next 120 seconds\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n",
      "(launch)\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /~ubuntu/scikic/api.cgi was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.7 (Ubuntu) Server at production-backend-lb-no-ssl-1389362950.eu-west-1.elb.amazonaws.com Port 80</address>\n",
      "</body></html>\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-18c64302d426>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mThread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m120.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "def myfunc(i):\n",
    "    print \"(launch)\"\n",
    "    questions_asked = [{'dataset':'postal','dataitem':'postcode','detail':'','answer':'s63af'}]\n",
    "    unprocessed_questions = [{'dataset':'postal','dataitem':'postcode','detail':'','answer':'s63af'}]\n",
    "    facts = {}\n",
    "        \n",
    "    data = {'questions_asked':questions_asked,'unprocessed_questions':unprocessed_questions,'facts':facts}\n",
    "    payload = {\"version\":1, 'data': data, 'apikey': 'YOUR_API_KEY_HERE', 'action':'inference'}\n",
    "    url = \"http://api.scikic.org\"\n",
    "    r = requests.post(url,json=payload)\n",
    "    print r.content\n",
    "\n",
    "it = 240\n",
    "for itn in range(1,600):\n",
    "    print \"Launching %d processes over the next 120 seconds\" % it\n",
    "    for i in range(it):\n",
    "        t = Thread(target=myfunc, args=(i,))\n",
    "        t.start()\n",
    "        time.sleep(120./it)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Questions\n",
    "\n",
    "- What happens if a class doesn't return a None question (but instead actually has a question)? But it also needs processing?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
